In this course we will consider five different types of agent: 1. Reactive Agent 2. Model-Based Agent 3. Planning Agent 4. Game Playing Agent 5. Learning Agent
1. Choose the next action based only on what they currently perceive, using a policy or set of rules which are simple to apply 2. Sometimes pajoratively called simple reflex agents  but they can do surprisingly sophisticated things!  Swiss robots  simulated hockey
1. Reactive Agents have no memory or state:  unable to base decision on previous observations  may repeat the same sequence of actions over and over 2. This phenomenon can also be observed in nature:  wasp dragging stung grasshopper into its nest
An agent with a world model but no planning can look into the past, but not into the future; it will perform poorly when the task requires any of the following: 1. searching several moves ahead  Chess, Rubikâ€™s cube 2. complex tasks requiring many individual steps  cooking a meal, assembling a watch 3. logical reasoning to achieve goals  travel to New York
1. Sometimes an agent may appear to be planning ahead but is actually just applying reative rules. if( Glitter ) then Grab else if( Stench ) then Shoot else randomly Left, Right or Forward 2. These rules can be hand-coded, or learned from experience. 3. Agent may appear intelligent, but is not exible in adapting to new situations.
1. Learning is not a separate module, but rather a set of techniques for improving the existing modules 2. Learning is necessary because:  may be difficult or even impossible for a human to design all aspects of the system by hand  the agent may need to adapt to new situations without being re-programmed by a human
We must distinguish complexity of learning from complexity of application. The policy for the simulated hockey player took several days of computation to derive (in this case, by evolutionary computation) but, once derived, it can be applied in real time.
