1. Logic in general – models and entailment 2. Propositional Logic 3. Equivalence, Validity, Satisﬁability 4. Inference Rules and Theorem Proving 5. Resolution and Conjunctive Normal Form 6. Forward and Backward Chaining 7. First Order Logic 8. Universal and Existential Quantiﬁers 9. Situation Calculus (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 1 )
We previously used a transition table for our World Model, with Planning done by State-Based Search (BFS, DFS, UCS, IDS, Greedy, A*, etc.) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 2 )
Some environments instead require a Knowledge Base of facts and a set of Logical Inference Rules to reason about those facts. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 3 )
P? P B OK P? OK A A A Need to represent: OK S OK A W 1. Facts: “Breeze in Square (1,2)”, “Stench in Square (2,1)” 2. Inference Rules: “If there is a Breeze in Square (1,2) then there is a Wumpus in Square (1,1), (2,2) or (1,3)”. Then try to deduce, for example, whether it is safe to move into Square (2,2). (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 4 )
Inference engine domain−independent algorithms Knowledge base domain−specific content A Knowledge Base is a set of sentences in a formal language. It takes a Declarative approach to building an agent (or other system): 1. Tell the system what it needs to know, then it can Ask itself what it needs to do 2. Answers should follow from the KB. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 5 )
P? B OK A A P? P? OK B OK A P? 1. If there is a Breeze in (1,2) and (2,1), then there are no safe actions. 2. Assuming that pits are uniformly distributed, a pit is more likely in (2,2) than in (3,1). How much more likely? (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 6 )
S A If there is a Smell in (1,1), there is no safe square to move into. However, we can use logic to reason about future states. 1. Shoot straight ahead 2. Wumpus was there ⇒ dead ⇒ safe 3. Wumpus wasn’t there ⇒ safe (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 7 )
The agent must be able to: 1. represent states, actions, etc. 2. incorporate new percepts 3. update internal representations of the world 4. deduce hidden properties of the world 5. determine appropriate actions (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 8 )
Logics are formal languages for representing information such that conclusions can be drawn. Syntax deﬁnes the sentences in the language. Semantics deﬁne the “meaning” of sentences; i.e. deﬁne truth of a sentence in a world. For example, the language of arithmetic: x + 2 ≥ y is a sentence; x2 + y > is not a sentence x + 2 ≥ y is true iff the number x + 2 is no less than the number y x + 2 ≥ y is true in a world where x = 7, y = 1 x + 2 ≥ y is false in a world where x = 0, y = 6 (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 9 )
Entailment means that one thing follows from another: KB |= α Knowledge base KB entails sentence α if and only if α is true in all worlds where KB is true. e.g. the KB containing “the Moon is full” and “the tide is high” entails “Either the Moon is full or the tide is high”. e.g. x + y = 4 entails 4 = x + y Entailment is a relationship between sentences (i.e. syntax) that is based on semantics. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 10 )
Logicians typically think in terms of models, which are formally structured worlds with respect to which truth can be evaluated. We say m is a model of a sentence α if α is true in m M(α) is the set of all models of α Then KB |= α if and only if M(KB) ⊆ M(α) M(    ) x x x x x x x x x x x x x x x x xx x x x M(KB) x x x x x x x x x x x x x x x x x x x x x x x x x x (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 11 )
Situation after detecting nothing in [1,1], moving right, Breeze in [2,1] Consider possible combinations for ?s assuming only pits. ? ? B A A ? 3 Boolean choices ⇒ 8 possible combinations. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 12 )
KB = wumpus-world rules + observations (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 14 )
KB = wumpus-world rules + observations α1 = “[1,2] is safe”, KB |= α1, proved by model checking (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 15 )
KB = wumpus-world rules + observations α2 = “[2,2] is safe”, KB 6|= α2 (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 16 )
Propositional logic is the simplest logic—illustrates basic ideas. The proposition symbols P1, P2 etc are sentences. If S is a sentence, ¬S is a sentence (negation) If S1 and S2 are sentences, S1 ∧ S2 is a sentence (conjunction) If S1 and S2 are sentences, S1 ∨ S2 is a sentence (disjunction) If S1 and S2 are sentences, S1 ⇒ S2 is a sentence (implication) If S1 and S2 are sentences, S1 ⇔ S2 is a sentence (biconditional) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 17 )
Each model speciﬁes TRUE / FALSE for each proposition symbol. For example, if there are Pits in (1,2) and (2,2) but not (3,1) we would have the following assignments: E.g. P1,2 P2,2 P3,1 TRUE TRUE FALSE (With these symbols, 8 possible models, can be enumerated automatically.) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 18 )
Rules for evaluating truth with respect to a model m: ¬S is TRUE iff S1 ∧ S2 S1 ∨ S2 is TRUE iff is TRUE iff S1 ⇒ S2 is TRUE iff i.e. is FALSE iff S S1 S1 S1 S1 is FALSE is TRUE and is TRUE or is FALSE or is TRUE and S2 S2 S2 S2 is TRUE is TRUE is TRUE is FALSE S1 ⇔ S2 is TRUE iff S1 ⇒ S2 is TRUE and S2 ⇒ S1 is TRUE Simple recursive process evaluates an arbitrary sentence, e.g. ¬P1,2 ∧ (P2,2 ∨ P3,1) = TRUE ∧ (FALSE ∨ TRUE) = TRUE ∧ TRUE = TRUE (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 19 )
P Q ¬ P P ∧ Q P ∨ Q P ⇒ Q F F T T F T F T T T F F F F F T F T T T T T F T P Q “Fred is served alcohol” “Fred is over 18 years old” P ⇒ Q “If Fred is served alcohol, then he must be over 18” Implication is not a causal relationship, but a rule that needs to be checked. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 20 )
Let Pi, j be true if there is a pit in [i, j]. Let Bi, j be true if there is a breeze in [i, j]. ¬P1,1 ¬B1,1 B2,1 “Pits cause breezes in adjacent squares” (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 21 )
Let Pi, j be true if there is a pit in [i, j]. Let Bi, j be true if there is a breeze in [i, j]. ¬P1,1 ¬B1,1 B2,1 “Pits cause breezes in adjacent squares” B1,1 ⇔ (P1,2 ∨ P2,1) B2,1 ⇔ (P1,1 ∨ P2,2 ∨ P3,1) “A square is breezy if and only if there is an adjacent pit” (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 22 )
Inference Rules: generalization: p ⇒ p ∨ q specialization: p ∧ q ⇒ p Two sentences are logically equivalent iff true in same models: α ≡ β if and only if α |= β and β |= α (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 23 )
commutativity: p ∧ q ⇔ q ∧ p p ∨ q ⇔ q ∨ p associativity: p ∧ (q ∧ r) ⇔ (p ∧ q) ∧ r p ∨ (q ∨ r) ⇔ (p ∨ q) ∨ r distributivity: p ∧ (q ∨ r) ⇔ (p ∧ q) ∨ (p ∧ r) p ∨ (q ∧ r) ⇔ (p ∨ q) ∧ (p ∨ r) implication: (p ⇒ q) ⇔ (¬p ∨ q) idempotent: p ∧ p ⇔ p double negation: ¬¬p ⇔ p contradiction: p ∧ ¬p ⇔ FALSE p ∨ p ⇔ p excluded middle: p ∨ ¬p ⇔ TRUE de Morgan: ¬(p ∧ q) ⇔ (¬p ∨ ¬q) ¬(p ∨ q) ⇔ (¬p ∧ ¬q) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 24 )
A sentence is valid if it is true in all models, e.g. TRUE, A ∨ ¬A, A ⇒ A, (A ∧ (A ⇒ B)) ⇒ B Validity is connected to inference via the Deduction Theorem: KB |= α if and only if (KB ⇒ α) is valid A sentence is satisﬁable if it is true in some model e.g. (A ∨ B) ∧C A sentence is unsatisﬁable if it is true in no models e.g. A ∧ ¬A Satisﬁability is connected to inference via the following: KB |= α if and only if (KB ∧ ¬α) is unsatisﬁable i.e. prove α by reductio ad absurdum (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 25 )
Prove that: (A ∧ (B ⇒ C)) ⇔ (¬(A ⇒ B) ∨ (A ∧C)) (A ∧ (B ⇒ C)) ⇔ A ∧ (¬B ∨C) [implication] ⇔ (A ∧ ¬B) ∨ (A ∧C) [distributivity] ⇔ ¬(¬A ∨ B) ∨ (A ∧C) [de Morgan] ⇔ ¬(A ⇒ B) ∨ (A ∧C) [implication] (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 26 )
KB ⊢i α = sentence α can be derived from KB by procedure i Soundness: i is sound if whenever KB ⊢i α, it is also true that KB |= α Completeness: i is complete if whenever KB |= α, it is also true that KB ⊢i α Consequences of KB are a haystack; α is a needle. Entailment = needle in haystack; inference = ﬁnding it. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 27 )
In order to apply Resolution, we must ﬁrst convert the KB into Conjunctive Normal Form (CNF). This means that the KB is a conjunction of clauses, and each clause is a disjunction of (possibly negated) literals. e.g. (A ∨ ¬B) ∧ (B ∨ ¬C ∨ ¬D) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 28 )
B1,1 ⇔ (P1,2 ∨ P2,1) 1. Eliminate ⇔ , replacing α ⇔ β with (α ⇒ β) ∧ (β ⇒ α). (B1,1 ⇒ (P1,2 ∨ P2,1)) ∧ ((P1,2 ∨ P2,1) ⇒ B1,1) 2. Eliminate ⇒ , replacing α ⇒ β with ¬α ∨ β. (¬B1,1 ∨ P1,2 ∨ P2,1) ∧ (¬(P1,2 ∨ P2,1) ∨ B1,1) 3. Move ¬ inwards using de Morgan’s rules and double-negation: (¬B1,1 ∨ P1,2 ∨ P2,1) ∧ ((¬P1,2 ∧ ¬P2,1) ∨ B1,1) 4. Apply distributivity law (∨ over ∧) and ﬂatten: (¬B1,1 ∨ P1,2 ∨ P2,1) ∧ (¬P1,2 ∨ B1,1) ∧ (¬P2,1 ∨ B1,1) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 29 )
Suppose we have two disjunctive clauses ℓ1 ∨ . . . ∨ ℓi ∨ . . . ∨ ℓk and m1 ∨ . . . ∨ m j ∨ . . . ∨ mn We can then derive a new clause by eliminating li, m j and combining all the other literals, i.e. ℓ1 ∨ . . . ∨ ℓi ∨ . . . ∨ ℓk, m1 ∨ . . . ∨ m j ∨ . . . ∨ mn ℓ1 ∨ . . . ∨ ℓi−1 ∨ ℓi+1 ∨ . . . ∨ ℓk ∨ m1 ∨ . . . ∨ m j−1 ∨ m j+1 ∨ . . . ∨ mn where ℓi and m j are complementary literals. e.g. P1,3 ∨ P2,2, ¬P2,2 P1,3 Resolution is sound and complete for propositional logic. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 30 )
Use resolution to prove that if there is a Breeze in (1,1), there must also be a Breeze in (2,2), i.e. prove (¬B1,1 ∨ B2,2), from this KB: (¬B1,1 ∨P1,2 ∨P2,1)∧(¬P1,2 ∨B1,1)∧(¬P2,1 ∨B1,1)∧(¬P1,2 ∨B2,2)∧(¬P2,1 ∨B2,2) Answer: ¬B1,1 ∨ P1,2 ∨ P2,1 , ¬P1,2 ∨ B2,2 ¬B1,1 ∨ P2,1 ∨ B2,2 ¬B1,1 ∨ P2,1 ∨ B2,2 , ¬P2,1 ∨ B2,2 ¬B1,1 ∨ B2,2 ∨ B2,2 The last clause is equivalent to ¬B1,1 ∨ B2,2 (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 31 )
Resolution provides us an alternative proof method which is generally somewhat faster than Truth Table Enumeration: 1. convert the into Conjunctive Normal Form, 2. add the negative of the clause you are trying to prove, 3. continually apply a series of resolutions until either (a) you derive the empty clause, or (b) no more pairs of clauses to which resolution can be applied (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 32 )
Model Checking can be done more efﬁciently if the clauses in the all happen to be in a special form for example they may all be Horn Clauses. Each Horn Clause is an implication involving only positive literals, in the form: (conjunction of symbols) ⇒ symbol e.g. C ∧ (B ⇒ A) ∧ (C ∧ D ⇒ B) Deduction with Horn Clauses can be done by Modus Ponens: p1, . . . , pn , p1 ∧ . . . ∧ pn ⇒ q q Efﬁcient Proof Methods, using Horn Clauses, can generally be divided into Forward Chaining and Backward Chaining. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 33 )
Look for a rule p1 ∧ . . . ∧ pn ⇒ q such that all the clauses on the left hand side are already in the KB. Apply this rule, and add q to the KB. Repeat this process until the goal clause α has been derived (or we run out of rules to apply). (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 34 )
Backward Chaining instead maintains a list of subgoals that it is trying to prove. Initially, this list consists of the ultimate goal α. Choose a clause q from the list of subgoals. 1. check if q is known already 2. otherwise, ﬁnd a rule with q on the right side and add clauses from the left side of this rule as new subgoals 3. check to make sure each new subgoal is not on the list already, and has not already been proved, or failed (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 35 )
Forward Chaining is data-driven automatic, unconscious processing e.g. object recognition, routine decisions 1. May do lots of work that is irrelevant to the goal Backward Chaining is goal-driven, appropriate for problem-solving 2. e.g. Where are my keys? How do I get into a PhD program? (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 36 )
Suppose you are given a KB written in 3-CNF. (This means Conjunctive Normal Form, with at most three literals in each clause.) Does there exist any assignment of truth values to the symbols which will make all of the clauses in the KB TRUE? For example, is there an assignment of truth values to A, B,C, D, E which will make the following TRUE? (¬D∨¬B∨C)∧(B∨¬A∨¬C)∧(¬C ∨¬B∨E)∧(E ∨¬D∨B)∧(B∨E ∨¬C) This provides a classic example of a Constraint Satisfaction Problem, to which methods such as Hill Climbing or Simulated Annealing can be applied. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 37 )
Difﬁculty of ﬁnding a solution depends on the ratio (m/n) where m is the number of clauses and n is the number of distinct symbols. Suppose n = 50 and the KB is in 3-CNF. 1. m/n < 4.3 ⇒ under-constrained 2. m/n ≃ 4.3 ⇒ critically difﬁcult 3. m/n > 4.3 ⇒ over-constrained Other CSPs like n-Queens are sometimes converted to 3-CNF, as a way of measuring whether they are under- or over-constrained. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 38 )
Logical agents apply inference to a knowledge base to derive new information and make decisions. Basic concepts of logic: 1. syntax: formal structure of sentences 2. semantics: truth of sentences wrt models 3. entailment: necessary truth of one sentence given another 4. inference: deriving sentences from other sentences 5. soundness: derivations produce only entailed sentences 6. completeness: derivations can produce all entailed sentences (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 39 )
“A square is breezy if and only if there is an adjacent pit.” This statement must be converted into a separate sentence for each square: B1,1 ⇔ (P1,2 ∨ P2,1) B2,1 ⇔ (P1,1 ∨ P2,2 ∨ P3,1) ... What we really want is a way to express such a statement in one sentence for all squares, e.g. Breezy(i, j) ⇔ (Pit(i − 1, j) ∨ Pit(i + 1, j) ∨ Pit(i, j − 1) ∨ Pit(i, j + 1)) First-Order Logic will allow us to do this. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 40 )
1. Objects: people, houses, numbers, theories, colors, football games, wars, centuries . . . 2. Predicates: red, round, bogus, prime, multistoried, . . . brother of, bigger than, inside, part of, has color, occurred after, owns, comes between, . . . 3. Functions: father of, best friend, third inning of, one more than, . . . (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 41 )
Language Ontology Epistemology Propositional logic facts true / false / unknown First-order logic facts, objects, relations true / false / unknown Temporal logic facts, objects, relations, times true / false / unknown Probability theory facts degree of belief Fuzzy logic facts + degree of truth known interval value (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 42 )
Constants Gold,Wumpus, [1, 2], [3, 1], etc. Predicates Ad jacent(), Smell(), Breeze(), At() Functions Result() Variables x, y, a, t, . . . Connectives ∧ ∨ ¬ ⇒ ⇔ Equality Quantiﬁers = ∀ ∃ (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 43 )
Atomic sentence = predicate(term1, . . . ,termn) or term1 = term2 Term = f unction(term1, . . . ,termn) or constant or variable e.g. At(Agent, [1, 1], S0) Holding(Gold, S5) Complex sentences are made from atomic sentences using connectives ¬S, S1 ∧ S2, S1 ∨ S2, S1 ⇒ S2, S1 ⇔ S2 e.g. Pit(x) ∧ Ad jacent(x, y) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 44 )
∀hvariablesihsentencei Where there’s glitter, there’s gold: ∀x Glitter(x) ⇒ At(Gold, x) ∀x P is equivalent to the conjunction of instantiations of P Glitter([1, 1]) ⇒ At(Gold, [1, 1]) ∧ Glitter([1, 2]) ⇒ At(Gold, [1, 2]) ∧ Glitter([1, 3]) ⇒ At(Gold, [1, 3]) ∧ . . . (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 45 )
Typically, ⇒ is the main connective with ∀ Common mistake: using ∧ as the main connective with ∀ ∀x Glitter(x) ∧ At(Gold, x) means “There is Glitter everywhere and Gold everywhere.” (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 46 )
∃hvariablesihsentencei Some sheep are black ∃x Sheep(x) ∧ Black(x) ∃x P is equivalent to the disjunction of instantiations of P Sheep(Dolly) ∧ Black(Dolly) ∨ Sheep(Lassie) ∧ Black(Lassie) ∨ Sheep(Skippy) ∧ Black(Skippy) ∨ . . . (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 47 )
Typically, ∧ is the main connective with ∃ Common mistake: using ⇒ as the main connective with ∃ ∃x Sheep(x) ⇒ Black(x) is true if there is anyone who is not at sheep! (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 48 )
∀x∀y is the same as ∀y∀x (Why?) ∃x∃y is the same as ∃y∃x (Why?) ∃x∀y is not the same as ∀y∃x ∃x∀y Loves(x, y) “There is a person who loves everyone in the world” ∀y∃x Loves(x, y) “Everyone in the world is loved by at least one person” Quantiﬁer duality: each can be expressed using the other ∀x Likes(x, IceCream) ¬∃x ¬Likes(x, IceCream) ∃x Likes(x, Broccoli) ¬∀x ¬Likes(x, Broccoli) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 49 )
Brothers are siblings “Sibling” is symmetric One’s mother is one’s female parent A ﬁrst cousin is a child of a parent’s sibling (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 50 )
Brothers are siblings ∀x, y Brother(x, y) ⇒ Sibling(x, y) “Sibling” is symmetric ∀x, y Sibling(x, y) ⇔ Sibling(y, x) One’s mother is one’s female parent ∀x, y Mother(x, y) ⇔ (Female(x) ∧ Parent(x, y)) A ﬁrst cousin is a child of a parent’s sibling ∀x, yFirstCousin(x, y) ⇔ ∃p, ps Parent(p, x) ∧ Sibling(p, q) ∧ Parent(q, y) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 51 )
Properties of locations: ∀x,t At(Agent, x,t) ∧ Smell(t) ⇒ Smelly(x) ∀x,t At(Agent, x,t) ∧ Breeze(t) ⇒ Breezy(x) ∀x,t At(Agent, x,t) ∧ Glitter(t) ⇒ AtGold(x) Squares are breezy near a pit: Causal rule – infer effect from cause ∀x, y Pit(x) ∧ Ad jacent(x, y) ⇒ Breezy(y) Diagnostic rule – infer cause from effect ∀y Breezy(y) ⇒ ∃x Pit(x) ∧ Ad jacent(x, y) Deﬁnition for the Breezy predicate (combines Causal and Diagnostic): ∀y Breezy(y) ⇔ [∃x Pit(x) ∧ Ad jacent(x, y)] (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 52 )
Facts hold only in certain situations, not universally. e.g. Holding(Gold, Now) rather than just Holding(Gold) Situation calculus is one way to represent change: 1. Adds a situation argument to each non-eternal predicate 2. e.g. Now denotes a situation in Holding(Gold, Now) Situations are connected by the Result function Result(a, s) is the situation that results from doing action a is state s PIT Gold PIT PIT Gold PIT PIT S 1 Forward PIT S 0 (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 53 )
We can plan a series of actions in a logical domain in a manner analogous to the Path Search algorithms discussed in Weeks 3 & 4. But, instead of the successor state being explicitly speciﬁed, we instead need to deduce what will be true and false in the state resulting from the previous state and action: Effect axiom describe changes due to action ∀s AtGold(s) ⇒ Holding(Gold, Result(Grab, s)) (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 54 )
Frame problem: Some facts will change as a result of an action, but many more will stay as they were. ∀s HaveArrow(s) ⇒ HaveArrow(Result(Grab, s)) However, adding too many of these frame axioms can make the process unmanageable. For example, if a cup is red, and you turn it upside down, it is still red. But, if a cup is full of water, and you turn it upside down, it is no longer full of water. Large-scale expert systems of the 1980’s often failed because of their inability to encode this kind of “commonsense” reasoning in explicit rules. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 55 )
Qualiﬁcation problem: Normally, we expect actions to have a certain effect. But, in the real world there could be endless caveats. What happens if the gold is slippery, or nailed down, or too heavy, or you can’t reach it, etc. Ramiﬁcation problem: Real actions have many secondary consequences – what about the dust on the gold, wear and tear on gloves, shoes, etc.. In general, we assume that a fact is true if a rule tells us that an action made it true, or if it was true before and no action made it false. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 56 )
Initial condition in KB (knowledge base): At(Agent, [1, 1], S0) At(Gold, [1, 2], S0) Query: Ask(KB, ∃s Holding(Gold, s)) i.e., in what situation will I be holding the gold? Answer: s = Result(Grab, Result(Forward, S0)) i.e., go forward and then grab the gold This assumes that the agent is interested in plans starting at S0 and that S0 is the only situation described in the KB. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 57 )
Represent plans as action sequences [a1, a2, . . . , an] PlanResult(p, s) is the result of executing p in s Then the query Ask(KB, ∃p Holding(Gold, PlanResult(p, S0))) has the solution p = [Forward, Grab] Deﬁnition of PlanResult in terms of Result: ∀s PlanResult([], s) = s ∀a, p, s PlanResult([a|p], s) = PlanResult(p, Result(a, s)) Planning systems are special-purpose reasoners designed to do this type of inference more efﬁciently than a general-purpose reasoner. (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 58 )
1. First Order Logic: ◮ objects and relations are semantic primitives ◮ syntax: constants, functions, predicates, equality, quantiﬁers 2. Increased expressive power: sufﬁcient to deﬁne Wumpus World 3. Situation calculus: ◮ conventions for describing actions and change ◮ can formulate planning as inference on a knowledge base (If you want to find more, please check in the lecture notes 7a_Logic.pdf Page 59 )
