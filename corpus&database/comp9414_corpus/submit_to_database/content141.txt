General Search algorithm: 1. add initial state to queue 2. repeat:  take node from front of queue  test if it is a goal state; if so, terminate  expand it, i.e. generate successor nodes and add them to the queue Search strategies are distinguished by the order in which new nodes are added to the queue of nodes awaiting expansion.
1. BFS and DFS treat all new nodes the same way:  BFS add all new nodes to the back of the queue  DFS add all new nodes to the front of the queue 2. (Seemingly) Best First Search uses an evaluation function f () to order the nodes in the queue; we have seen one example of this:  UCS f (n) = cost g(n) of path from root to node n 3. Informed or Heuristic search strategies incorporate into f () an estimate of distance to goal  Greedy Search f (n) = estimate h(n) of cost from node n to goal  A Search f (n) = g(n) + h(n)
Oradea 71 Zerind 151 75 Arad 140 Neamt 87 118 Timisoara 111 70 75 Sibiu 99 Fagaras 80 Rimnicu Vilcea Lugoj 97 Pitesti 211 Mehadia 146 101 85 Dobreta 120 138 Craiova Bucharest 90 Giurgiu Iasi 92 142 98 Urziceni Straightline distance to Bucharest Arad Bucharest Craiova Dobreta Eforie Fagaras Giurgiu Hirsova Iasi Lugoj Mehadia Neamt Oradea Pitesti Rimnicu Vilcea Sibiu Timisoara Urziceni Vaslui Zerind 366  0 160 242 161 178 77 151 226 244 241 234 380 98 193 253 329 80 199 374 Vaslui Hirsova 86 Eforie
There is a whole family of Best First Search algorithms with different evaluation functions f (). A key component of these algorithms is a heuristic function: 1. Heuristic function h: {Set of nodes}  R :  h(n) = estimated cost of the cheapest path from current node n to goal node.  in the area of search, heuristic functions are problem specic functions that provide an estimate of solution cost.
1. Greedy Best-First Search: Best-First Search that selects the next node for expansion using the heuristic function for its evaluation function, i.e. f (n) = h(n) 2. h(n) = 0  n is a goal state 3. i.e. greedy search minimises the estimated cost to the goal; it expands whichever node n is estimated to be closest to the goal. 4. Greedy: tries to bite off as big a chunk of the solution as possible, without worrying about long-term consequences.
1. hSLD(n) = straight-line distance between n and the goal location (Bucharest). 2. Assume that roads typically tend to approximate the direct connection between two cities. 3. Need to know the map coordinates of the cities:  p(Sibiux  Bucharestx)2 + (Sibiuy  Bucharesty)2
Arad 366 Zerind Sibiu Timisoara 374 253 329
Arad 366 Zerind Sibiu Timisoara 374 253 329 Arad Oradea Fagaras Rimnicu  Vilcea 366 380 178 193
Arad 366 Zerind Sibiu Timisoara 374 253 329 Arad Oradea Fagaras Rimnicu  Vilcea 366 380 178 193 Sibiu Bucharest 253 0
Try 1. Iasi to Fagaras 2. Fagaras to Iasi 3. Rimnicu Vilcea to Lugoj
1. Complete: No! can get stuck in loops, e.g., Iasi  Neamt  Iasi  Neamt  ... Complete in nite space with repeated-state checking 2. Time: O(bm), where m is the maximum depth in search space. 3. Space: O(bm) (retains all nodes in memory) 4. Optimal: No! e.g., the path Sibiu  Fagaras  Bucharest is 32 km longer than Sibiu  Rimnicu Vilcea  Pitesti  Bucharest. Therefore Greedy Search has the same decits as Depth-First Search. However, a good heuristic can reduce time and memory costs substantially.
1. Expand root rst, then expand least-cost unexpanded node 2. Implementation: QUEUEINGFN = insert nodes in order of increasing path cost. 3. Reduces to breadth-rst search when all actions have same cost 4. Finds the cheapest goal provided path cost is monotonically increasing along each path (i.e. no negative-cost steps)
Arad 75 140 118 Zerind Sibiu Timisoara
Arad 75 140 118 Zerind Sibiu Timisoara 75 71 118 111 Arad Oradea Arad Lugoj
1. Complete? Yes, if b is nite and step costs   with  > 0. 2. Optimal? Yes. 3. Guaranteed to nd optimal solution, but does so by exhaustively expanding all nodes closer to the initial state than the goal. Q: can we still guarantee optimality but search more efciently, by giving priority to more promising nodes?
1. A Search uses evaluation function f (n) = g(n) + h(n)  g(n) = cost from initial node to node n  h(n) = estimated cost of cheapest path from n to goal  f (n) = estimated total cost of cheapest solution through node n 2. Greedy Search minimizes h(n)  efcient but not optimal or complete 3. Uniform Cost Search minimizes g(n)  optimal and complete but not efcient
1. A* Search minimizes f (n) = g(n) + h(n)  idea: preserve efciency of Greedy Search but avoid expanding paths that are already expensive 2. Q: is A Search optimal and complete ? 3. A: Yes! provided h() is admissible in the sense that it never overestimates the cost to reach the goal.
Arad 366 75 140 118 Zerind Sibiu Timisoara 449 393 447
Arad 366 75 140 118 Zerind Sibiu Timisoara 449 393 447 140 99 151 80 Arad Oradea Fagaras Rimnicu  Vilcea 646 526 417 413
Arad 366 75 140 118 Zerind Sibiu Timisoara 449 393 447 140 99 151 80 Arad Oradea Fagaras 646 526 417 Rimnicu  Vilcea 413 146 97 80 Craiova Pitesti Sibiu 526 415 553
Arad 366 75 140 118 Zerind Sibiu Timisoara 449 393 447 140 99 151 80 Arad Oradea Fagaras 646 526 417 Rimnicu  Vilcea 413 146 97 80 Craiova Pitesti Sibiu 526 415 553 97 138 101 Rimnicu  Vilcea Craiova Bucharest 607 615 418
Arad 366 75 140 118 Zerind Sibiu Timisoara 449 393 447 140 99 151 80 Arad Oradea Fagaras 646 526 417 99 211 Rimnicu  Vilcea 413 146 97 80 Sibiu Bucharest Craiova Pitesti Sibiu 591 450 526 415 553 97 138 101 Rimnicu  Vilcea Craiova Bucharest 607 615 418
1. Heuristic h() is called admissible if n h(n)  h(n) where h(n) is true cost from n to goal 2. If h is admissible then f (n) never overestimates the actual cost of the best solution through n. 3. Example: hSLD() is admissible because the shortest path between any two points is a line. 4. Theorem: A Search is optimal if h() is admissible.
Suppose a suboptimal goal node G2 has been generated and is in the queue. Let n be the last unexpanded node on a shortest path to an optimal goal node G. Start n G G 2 f (G2) = g(G2) since h(G2) = 0 > g(G) since G2 is suboptimal  f (n) since h is admissible.
Since f (G2) > f (n), A will never select G2 for expansion. Note: suboptimal goal node G2 may be generated, but it will never be expanded. In other words, even after a goal node has been generated, A will keep searching so long as there is a possibility of nding a shorter solution. Once a goal node is selected for expansion, we know it must be optimal, so we can terminate the search.
1. Complete: Yes, unless there are innitely many nodes with f  cost of solution. 2. Time: Exponential in [relative error in h length of solution] 3. Space: Keeps all nodes is memory 4. Optimal: Yes (assuming h() is admissible).
1. Iterative Deepening A is a low-memory variant of A which performs a series of depth-rst searches, but cuts off each search when the sum f () = g() + h() exceeds some pre-dened threshold. 2. The threshold is steadily increased with each successive search. 3. IDA is asymptotically as efcient as A for domains where the number of states grows exponentially.
What sort of search will greedy search emulate if we run it with: 1. h(n) = g(n) ? 2. h(n) = g(n) ? 3. h(n) = number of steps from initial state to node n ?
e.g. for the 8-puzzle: h1(n) = total number of misplaced tiles h2(n) = total Manhattan distance = distance from goal position 7 5 8 2 3 4 6 1 3 6 51 4 7 2 5 8 Start State Goal State h1(S) = ? h2(S) = ? 1. Why are h1, h2 admissible?
e.g. for the 8-puzzle: h1(n) = total number of misplaced tiles h2(n) = total Manhattan distance = distance from goal position 7 5 8 2 3 4 6 1 h1(S) = 6 h2(S) = 4+0+3+3+1+0+2+1 = 14 Start State 3 6 51 4 7 2 5 8 Goal State 1. h1: every tile must be moved at least once. 2. h2: each action can only move one tile one step closer to the goal.
1. if h2(n)  h1(n) for all n (both admissible) then h2 dominates h1 and is better for search. So the aim is to make the heuristic h() as large as possible, but without exceeding h(). 2. typical search costs: 14-puzzle 24-puzzle IDS A(h1) A(h2) IDS A(h1) A(h2) = 3,473,941 nodes = 539 nodes = 113 nodes  54  109 nodes = 39,135 nodes = 1,641 nodes
1. Admissible heuristics can often be derived from the exact solution cost of a simplied or relaxed version of the problem. (i.e. with some of the constraints weakened or removed)  If the rules of the 8-puzzle are relaxed so that a tile can move anywhere, then h1(n) gives the shortest solution.  If the rules are relaxed so that a tile can move to any adjacent square, then h2(n) gives the shortest solution.
1. Let h1, h2, ..., hm be admissible heuristics for a given task. 2. Dene the composite heuristic h(n) = max(h1(n), h2(n), ..., hm(n)) 3. h is admissible 4. h dominates h1, h2, ..., hm
1. 3D Manhattan distance, but to be admissible need to divide by 8. 2. better to take 3D Manhattan distance for edges only, divided by 4. 3. alternatively, max of 3D Manhattan distance for edges and corners, divided by 4 (but the corners slow down the computation without much additional benet). 4. best approach is to pre-compute Pattern Databases which store the minimum number of moves for every combination of the 8 corners, and for two sets of 6 edges. 5. to save memory, use IDA. Finding Optimal Solutions to Rubiks Cube using Pattern Databases (Korf, 1997)
1. Heuristics can be applied to reduce search cost. 2. Greedy Search tries to minimize cost from current node n to the goal. 3. A combines the advantages of Uniform-Cost Search and Greedy Search. 4. A is complete, optimal and optimally efcient among all optimal search algorithms. 5. Memory usage is still a concern for A. IDA is a low-memory variant.
