1. Uncertainty 2. Probability 3. Syntax and Semantics 4. Inference 5. Conditional Independence 6. Bayes Rule c(cid:13)AIMA, 2004, Alan Blair, 2013-18
In many situations, an AI agent has to choose an action based on incomplete information. 1. stochastic environments (e.g. dice rolls in Backgammon) 2. partial observability  some aspects of environment hidden from agent  robots can have noisy sensors, reporting quantities which differ from the true values c(cid:13)AIMA, 2004, Alan Blair, 2013-18
P? B OK A A P? P? OK B OK A P? In this situation no action is completely safe, because the agent does not know the location of the Pit(s). c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Let action At = leave for airport t minutes before ight Will At get me there on time? Problems: 1. partial observability, noisy sensors 2. uncertainty in action outcomes (at tyre, etc.) 3. immense complexity of modelling and predicting trafc Hence a purely logical approach either 1) risks falsehood: A30 will get me there on time, or 2) leads to conclusions that are too weak for decision making: A30 will get me there on time if theres no accident on the bridge and it doesnt rain and my tires remain intact etc etc. (A1440 might be safe but Id have to stay overnight in the airport . . .) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Default or nonmonotonic logic: Assume my car does not have a at tire, etc. Assume A30 works unless contradicted by evidence Issues: What assumptions are reasonable? How to handle contradiction? Probability Given the available evidence, A30 will get me there on time with probability 0.04 Mahaviracarya (9th C.), Cardamo (1565) theory of gambling c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Probabilistic assertions summarize effects of Laziness: failure to enumerate exceptions, qualications, etc. Ignorance: lack of relevant facts, initial conditions, etc. Subjective or Bayesian probability: Probabilities relate propositions to ones own state of knowledge e.g. P(A30|no reported accidents) = 0.06 These are not claims of a probabilistic tendency in the current situation (but might be learned from past experience of similar situations) Probabilities of propositions change with new evidence: e.g. P(A30|no reported accidents, 5 a.m.) = 0.15 (Analogous to logical entailment status KB |= , not absolute truth) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Suppose I believe the following: P(A30 gets me there on time| . . .) P(A90 gets me there on time| . . .) P(A120 gets me there on time| . . .) P(A1440 gets me there on time| . . .) Which action to choose? = = = = 0.04 0.70 0.95 0.9999 Depends on my preferences for missing ight vs. airport cuisine, etc. Utility theory is used to represent and infer preferences Decision theory = utility theory + probability theory c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Begin with a set   the sample space (e.g. 6 possible rolls of a die)    is a sample point/possible world/atomic event A probability space or probability model is a sample space with an assignment P() for every    s.t. 0  P()  1  P() = 1 e.g. P(1) = P(2) = P(3) = P(4) = P(5) = P(6) = 1 6 . An event A is any subset of  P(A) =  {A} P() e.g. P(die roll < 4) = P(1) + P(2) + P(3) = 1 6 + 1 6 + 1 6 = 1 2 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
A random variable (r.v.) is a function from sample points to some range (e.g. the Reals or Booleans) For example, Odd(3) = true. P induces a probability distribution for any r.v. X : P(X = xi) =  P() {:X()=xi} e.g., P(Odd = true) = P(1) + P(3) + P(5) = 1 6 + 1 6 + 1 6 = 1 2 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Think of a proposition as the event (set of sample points) where the proposition is true Given Boolean random variables A and B: event a = set of sample points where A() = true event a = set of sample points where A() = false event a b = points where A() = true and B() = true With Boolean variables, sample point = propositional logic model e.g., A = true, B = false, or ab. Proposition = disjunction of atomic events in which it is true e.g., (a b)  (a b) (ab) (a b)  P(a b) = P(a b) + P(ab) + P(a b) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
The denitions imply that certain logically related events must have related probabilities For example, P(a b) = P(a) + P(b) P(a b) True A >A     B B de Finetti (1931): an agent who bets according to probabilities that violate these axioms can be forced to bet so as to lose money regardless of outcome. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Propositional or Boolean random variables e.g., Cavity (do I have a cavity?) Cavity = true is a proposition, also written Cavity Discrete random variables (nite or innite) e.g., Weather is one of hsunny,rain,cloudy,snowi Weather = rain is a proposition Values must be exhaustive and mutually exclusive Continuous random variables (bounded or unbounded) e.g. Temp = 21.6; also allow, e.g. Temp < 22.0 Arbitrary Boolean combinations of basic propositions. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Prior or unconditional probabilities of propositions e.g. P(Cavity = true) = 0.1 and P(Weather = sunny) = 0.72 correspond to belief prior to arrival of any (new) evidence. Probability distribution gives values for all possible assignments: P(Weather) = h0.72, 0.1, 0.08, 0.1i (normalized, i.e., sums to 1) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Joint probability distribution for a set of r.v.s gives the probability of every atomic event on those r.vs (i.e., every sample point) P(Weather, Cavity) is a 4 2 matrix of values: cloudy Weather = snow sunny rain Cavity = true 0.144 0.02 0.016 Cavity = false 0.576 0.08 0.064 0.02 0.08 Every question about a domain can be answered by the joint distribution because every event is a sum of sample points. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Express distribution as a parameterized function. e.g. P(X = x) = U[18, 26](x) = uniform density between 18 and 26 0.125 18 dx 26 Here P is a density; integrates to 1. P(X = 20.5) = 0.125 really means lim dx0 P(20.5  X  20.5 + dx)/dx = 0.125 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
P(x) = 12 e(x)2/22 0 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
We consider an Agent whose World Model consists not of a set of facts, but rather a set of probabilities of certain facts being true, or certain random variables taking particular values. When the Agent makes an observation, it may update its World Model by adjusting these probabilities, based on what it has observed. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Assume you live in a community where, at any given time, 20% of people have a cavity in one of their teeth which needs a lling from the dentist. P(cavity) = 0.2 If you have a toothache, suddenly you will think it is much more likely that you have a cavity, perhaps as high as 60%. We say that the conditional probability of cavity, given toothache, is 0.6, written as follows: P(cavity| toothache) = 0.6 If you go to the dentist, they will use a small hook-shaped instrument called a probe, and check whether this probe can catch on the back of your tooth. If it does catch, this information will increase the probability that you have a cavity. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
We assume there is some underlying joint probability distribution over the three random variables Toothache, Cavity and Catch, which we can write in the form of a table: toothache L toothache catch catchL catch catchL cavity .108 .012 .072 .008 L cavity .016 .064 .144 .576 Note that the sum of the entries in the table is 1.0 . For any proposition , sum the atomic events where it is true: P() = :|= P() c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Start with the joint distribution: toothache L toothache catch catchL catch catchL cavity .108 .012 .072 .008 L cavity .016 .064 .144 .576 For any proposition , sum the atomic events where it is true: P() = :|= P() P(toothache) = 0.108 + 0.012 + 0.016 + 0.064 = 0.2 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
toothache L toothache catch catchL catch catchL cavity .108 .012 .072 .008 L cavity .016 .064 .144 .576 For any proposition , sum the atomic events where it is true: P() = :|= P() P(cavity toothache) = 0.108 + 0.012 + 0.072 + 0.008 + 0.016 + 0.064 = 0.28 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
If we consider two random variables a and b, with P(b) 6= 0, then the conditional probability of a given b is P(a|b) = P(a b) P(b) Alternative formulation: P(a b) = P(a|b)P(b) = P(b|a)P(a) When an agent considers a sequence of random variables at successive time steps, they can be chained together using this formula repeatedly: P(Xn, . . . , X1) = P(Xn| Xn1, . . . , X1)P(Xn1, . . . , X1) = P(Xn| Xn1, . . . , X1)P(Xn1| Xn2, . . . , X1) = . . . = n  i=1 P(Xi| Xi1, . . . , X1) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
toothache L toothache catch catchL catch catchL cavity .108 .012 .072 .008 L cavity .016 .064 .144 .576 P(cavity| toothache) = = P(cavity toothache) P(toothache) 0.016 + 0.064 0.108 + 0.012 + 0.016 + 0.064 = 0.4 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Lets consider the joint probability distribution for Cavity and Weather. Weather = sunny rain cloudy snow Cavity = true 0.144 0.02 0.016 Cavity = false 0.576 0.08 0.064 0.02 0.08 Note that: P(cavity|Weather = sunny) = 0.144 0.144 + 0.576 = 0.2 = P(cavity) In other words, learning that the Weather is sunny has no effect on the probability of having a cavity (and the same for rain, cloudy and snow). We say that Cavity and Weather are independent variables. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
A and B are independent iff P(A|B) = P(A) or P(B|A) = P(B) or P(A, B) = P(A)P(B) Cavity Toothache Catch Weather decomposes into Toothache Catch Cavity Weather If variables not independent, would need 32 items in probability table. Because Weather is independent of the other variables, only need two smaller tables, with a total of 8+4=12 items. P(Toothache, Catch, Cavity, Weather) = P(Toothache, Catch, Cavity)P(Weather) (Note: the number of free parameters is slightly less, because the values in each table must sum to 1). c(cid:13)AIMA, 2004, Alan Blair, 2013-18
The variables Toothache, Cavity and Catch are not independent. But, they do exhibit conditional independence. If you have a cavity, the probability that the probe will catch is 0.9, no matter whether you have a toothache or not. If you dont have a cavity, the probability that the probe will catch is 0.2, regardless of whether you have a toothache. In other words, P(Catch| Toothache, Cavity) = P(Catch| Cavity) We say that Catch is conditionally independent of Toothache given Cavity. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
This conditional independence reduces the number of free parameters from 7 down to 5. For larger problems with many variables, deducing this kind of conditional independence among the variables can reduce the number of free parameters substantially, and allow the Agent to maintain a simpler World Model. Equivalent statements: P(Toothache|Catch, Cavity) = P(Toothache|Cavity) P(Toothache, Catch|Cavity) = P(Toothache|Cavity)P(Catch|Cavity) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
The formula for conditional probability can be manipulated to nd a relationship when the two variables are swapped: P(a b) = P(a| b)P(b) = P(b| a)P(a)  Bayes rule P(a| b) = P(b| a)P(a) P(b) This is often useful for assessing the probability of an underlying cause after an effect has been observed: P(Cause|Effect) = P(Effect|Cause)P(Cause) P(Effect) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Question: Suppose we have a 98% accurate test for a type of cancer which occurs in 1% of patients. If a patient tests positive, what is the probability that they have the cancer? Answer: There are two random variables: Cancer (true or false) and Test (positive or negative). The probability is called a prior, because it represents our estimate of the probability before we have done the test (or made some other observation). We interpret the statement that the test is 98% accurate to mean: P(positive| cancer) = 0.98, and P(negative|cancer) = 0.98 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Pos P(Yes,Pos) = 0.01 Cancer? Yes No 0.01 0.99 Test Test Neg Pos 0.98 0.02 0.02 0.98 P(Yes,Neg) = 0.00 P(No ,Pos)  = 0.02 Neg P(No ,Neg) = 0.97 P(cancer| positive) = P(positive| cancer)P(cancer) P(positive) = 0.98 0.01 0.98 0.01 + 0.2 0.99 = 0.01 0.01 + 0.02 = 1 3 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
P(cavity, toothache, catch) = P(toothache| catch, cavity)P(catch| cavity)P(cavity) = P(toothache|cavity)P(catch|cavity)P(cavity) This is an example of a naive Bayes model: P(Cause, Effect1, . . . , Effectn) = P(Cause) i P(Effecti|Cause) Cavity Cause Toothache Catch Effect 1 Effect n Total number of parameters is linear in n c(cid:13)AIMA, 2004, Alan Blair, 2013-18
 1,4  2,4  3,4  4,4  1,3  2,3  3,3  4,3  1,2 B OK  1,1 OK  2,2  3,2  4,2  3,1  4,1  2,1 B OK What is the probability of a Pit in (1,3) ? What about (2,2) ? To answer this, we need a prior assumption about the placement of Pits. We will assume a 20% chance of a Pit in each square at the beginning of the game (independent of what Pits are in the other squares). c(cid:13)AIMA, 2004, Alan Blair, 2013-18
We will use Bi, j to indicate a Breeze in square (i, j), and Piti, j to indicate a Pit in square (i, j). We use known to represent what we know, i.e. B1,2  B2,1 B1,1 Pit1,2 Pit2,1 Pit1,1 We use Unknown to represent the joint probability of Pits in all the other squares, i.e. P(Unknown) = P(Pit1,4, . . . , Pit4,1) We divide Unknown into Fringe and Other, where P(Fringe) = P(Pit1,3, Pit2,2, Pit3,1) and Other is all the other variables. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
P(Pit1,3, unknown| known) P(Pit1,3, fringe, other| known) P(Pit1,3| known) =  =   unknown fringe other =   fringe other P(Pit1,3| fringe, other, known) P(fringe, other| known) =  fringe P(Pit1,3| fringe)  other =  fringe P(Pit1,3| fringe)  other P(fringe, other| known) P(known| fringe, other)P(fringe, other) P(known) Note: have used the fact that P1,3 is independent of other, given fringe. c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Lets denote by F the set of fringe models compatible with the known facts:  1,3  1,2  2,2 B OK  1,1  2,1 OK B OK  1,3  1,2  2,2 B OK  1,3  1,2  2,2 B OK  1,3  1,2  2,2 B OK  1,3  1,2  2,2 B OK  3,1  1,1  2,1 OK B OK  3,1  1,1  2,1 OK B OK  3,1  1,1  2,1 OK  3,1  1,1  2,1 OK  3,1 B OK B OK 0.2 x 0.2 = 0.04 0.2 x 0.8 = 0.16 0.8 x 0.2 = 0.16 0.2 x 0.2 = 0.04 0.2 x 0.8 = 0.16 P(known| fringe, other) = 0 outside F, so P(Pit1,3| known) reduces to:  fringeF P(Pit1,3| fringe)  other Note also that P(known| fringe, other)P(fringe, other) P(known) P(known) =  fringeF  other P(known| fringe, other)P(fringe, other) c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Because of the prior, other and fringe become independent, and known becomes independent of other, given fringe. P(known| fringe, other) = P(known| fringe) = 1, for fringe  F, so P(fringe) = (0.2)3 + 3 (0.2)2(0.8) + (0.2)(0.8)2 P(known) =  fringeF = 0.008 + 0.032 + 0.032 + 0.032 + 0.128 = 0.232 The numerator includes only those models for which Pit1,3 is true, i.e. P(Pit1,3| known) = 0.008 + 0.032 + 0.032 0.232 = 9 29  0.310 In a similar way, P(Pit2,2| known) = 0.008 + 0.032 + 0.032 + 0.128 0.232 = 25 29  0.862 c(cid:13)AIMA, 2004, Alan Blair, 2013-18
Probability is a rigorous formalism for uncertain knowledge Joint probability distribution species probability of every atomic event Queries can be answered by summing over atomic events For nontrivial domains, we must nd a way to reduce the joint size Independence and conditional independence provide the tools c(cid:13)AIMA, 2004, Alan Blair, 2013-18
