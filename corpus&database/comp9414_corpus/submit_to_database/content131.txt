1. Reactive and Model-Based Agents choose their actions based only on what they currently perceive, or have perceived in the past. 2. a Planning Agent can use Search techniques to plan several steps ahead in order to achieve its goal(s). 3. two classes of search strategies:  Uninformed search strategies can only distinguish goal states from non-goal states  Informed search strategies use heuristics to try to get closer to the goal
Oradea Zerind Arad Sibiu Fagaras Timisoara Rimnicu Vilcea Pitesti Lugoj Mehadia Dobreta Craiova Giurgiu Neamt Iasi Vaslui Urziceni Bucharest Hirsova Eforie
On touring holiday in Romania; currently in Arad. Flight leaves tomorrow from Bucharest; non-refundable ticket. 1. Step 1 Formulate goal: be in Bucharest on time 2. Step 2 Specify task:  states: various cities  operators or actions (= transitions between states): drive between cities 3. Step 3 Find solution (= action sequences): sequence of cities, e.g. Arad, Sibiu, Fagaras, Bucharest 4. Step 4 Execute: drive through all the cities given by the solution.
A task is specied by states and actions: 1. state space e.g. other cities 2. initial state e.g. at Arad 3. actions or operators (or successor function S(x)) etc. e.g. Arad  Zerind Arad  Sibiu 4. goal test, check if a state is goal state In this case, there is only one goal specied (at Bucharest) 5. path cost e.g. sum of distances, number of actions etc.
1. Real world is absurdly complex  state space must be abstracted for problem solving 2. (abstract) state = set of real states 3. (abstract) action = complex combination of real actions  e.g. Arad  Zerind represents a complex set of possible routes, detours, rest stops, etc.  for guaranteed realizability, any real state in Arad must get to some real state in Zerind 4. (abstract) solution = set of real paths that are solutions in the real world
1. Toy problems: concise exact description 2. Real world problems: dont have a single agreed desription
7 5 8 2 3 4 6 1 3 6 51 4 7 2 5 8 Start State Goal State 1. states: ? 2. operators: ? 3. goal test: ? 4. path cost: ?
7 5 8 2 3 4 6 1 3 6 51 4 7 2 5 8 Start State Goal State 1. states: integer locations of tiles (ignore intermediate positions) 2. operators: move blank left, right, up, down (ignore unjamming etc.) 3. goal test: = goal state (given) 4. path cost: 1 per move
R R R P R R 1. states: ? 2. operators: ? 3. goal test: ? 4. path cost: ?
1. states: ? 2. operators: ? 3. goal test: ? 4. path cost: ?
Search: Finding state-action sequences that lead to desirable states. Search is a function Basic idea: solution search(task) Ofine, simulated exploration of state space by generating successors of already-explored states (i.e. expanding them)
1. Start with a priority queue consisting of just the initial state. 2. Choose a state from the queue of states which have been generated but not yet expanded. 3. Check if the selected state is a Goal State. If it is, STOP (solution has been found). 4. Otherwise, expand the chosen state by applying all possible transitions and generating all its children. 5. If the queue is empty, Stop (no solution exists). 6. Otherwise, go back to Step 2.
Arad Zerind Sibiu Timisoara Arad Oradea Fagaras Rimnicu  Vilcea Sibiu Bucharest
1. Search tree: superimposed over the state space. 2. Root: search node corresponding to the initial state. 3. Leaf nodes: correspond to states that have no successors in the tree because they were not expanded or generated no new nodes. 4. state space is not the same as search tree  there are 20 states = 20 cities in the route nding example  but there are innitely many paths!
One possibility is to have a node data structure with ve components: 1. Corresponding state 2. Parent node: the node which generated the current node. 3. Operator that was applied to generate the current node. 4. Depth: number of nodes from the root to the current node. 5. Path cost.
a state is (a representation of) a physical conguration a node is a data structure constituting part of a search tree includes parent, children, depth, path cost g(x) States do not have parents, children, depth, or path cost! parent, action Node depth = 6 g = 6 State 5 5 6 6 7 7 4 4 1 1 3 3 8 8 2 2 s t a t e Note: two different nodes can contain the same state.
Frontier: collection of nodes waiting to be expanded It can be implemented as a priority queue with the following operations: 1. MAKE-QUEUE(ITEMS) creates queue with given items. 2. Boolean EMPTY(QUEUE) returns TRUE if no items in queue. 3. REMOVE-FRONT(QUEUE) removes the item at the front of the queue and returns it. 4. QUEUEING-FUNCTION(ITEMS, QUEUE) inserts new items into the queue.
1. A strategy is dened by picking the order of node expansion 2. Strategies are evaluated along the following dimensions:  completeness  does it always nd a solution if one exists?  time complexity  number of nodes generated/expanded  space complexity  maximum number of nodes in memory  optimality  does it always nd a least-cost solution? 3. Time and space complexity are measured in terms of  b  maximum branching factor of the search tree  d  depth of the least-cost solution  m  maximum depth of the state space (may be )
How to compare algorithms ? Two approaches: 1. Benchmarking: run both algorithms on a computer and measure speed 2. Analysis of algorithms: mathematical analysis of the algorithm
1. Run two algorithms on a computer and measure speed. 2. Depends on implementation, compiler, computer, data, network ... 3. Measuring time 4. Processor cycles 5. Counting operations 6. Statistical comparison, condence intervals
1. T(n) is O( f (n)) means n0, k : n > n0 T(n)  k f (n)  n = input size  T(n) = total number of step of the algorithm 2. Independent of the implementation, compiler, ... 3. Asymptotic analysis: For large n, an O(n) algorithm is better than an O(n2) algorithm. 4. O() abstracts over constant factors  e.g. T(100  n + 1000) is better than T(n2 + 1) only for n > 110. 5. O() notation is a good compromise between precision and ease of analysis.
Uninformed (or blind) search strategies use only the information available in the problem denition (can only distinguish a goal from a non-goal state): 1. Breadth First Search 2. Uniform Cost Search 3. Depth First Search 4. Depth Limited Search 5. Iterative Deepening Search Strategies are distinguished by the order in which the nodes are expanded.
Informed (or heuristic) search strategies use task-specic knowledge. 1. Example of task-specic knowledge: distance between cities on the map. 2. Informed search is more efcient than Uninformed search. 3. Uninformed search systematically generates new states and tests them against the goal.
1. All nodes are expanded at a given depth in the tree before any nodes at the next level are expanded 2. Expand root rst, then all nodes generated by root, then All nodes generated by those nodes, etc. 3. Expand shallowest unexpanded node 4. implementation: QUEUEING-FUNCTION = put newly generated successors at end of queue 5. Very systematic 6. Finds the shallowest goal rst
Arad Zerind Sibiu Timisoara Arad Oradea Arad Oradea Fagaras Rimnicu  Vilcea Arad Lugoj
1. Complete? Yes (if b is nite the shallowest goal is at a xed depth d and will be found before any deeper nodes are generated) 2. Time: 1 + b + b2 + b3 + . . . + bd = bd+11 b1 = O(bd) 3. Space: O(bd) (keeps every node in memory; generate all nodes up to level d) 4. Optimal? Yes, but only if all actions have the same cost Space is the big problem for Breadth-First Search; it grows exponentially with depth!
Breadth First Search assumes that all steps have equal cost. Oradea 71 Zerind 151 75 Arad 140 118 Timisoara 111 70 75 Sibiu 99 Fagaras 80 Rimnicu Vilcea Lugoj 97 Pitesti 211 Mehadia 146 101 85 Dobreta 120 138 Craiova Bucharest 90 Giurgiu Neamt 87 Iasi 92 142 98 Urziceni Vaslui Hirsova 86 Eforie However, we are often looking for the path with the shortest total distance rather than the number of steps.
1. Expand root rst, then expand least-cost unexpanded node 2. Implementation: QUEUEINGFUNCTION = insert nodes in order of increasing path cost. 3. Reduces to Breadth First Search when all actions have same cost 4. Finds the cheapest goal provided path cost is monotonically increasing along each path (i.e. no negative-cost steps)
Arad 75 140 118 Zerind Sibiu Timisoara 75 71 118 111 Arad Oradea Arad Lugoj
1. Complete? Yes, if b is nite and step cost   with  > 0 2. Time: O(bC/) where C = cost of optimal solution, and assume every action costs at least  3. Space: O(bC/) (bC/ = bd if all step costs are equal) 4. Optimal? Yes.
1. Expands one of the nodes at the deepest level of the tree 2. Implementation:  QUEUEINGFUNCTION = insert newly generated states at the front of the queue (thus making it a stack)  can alternatively be implemented by recursive function calls
Arad Zerind Sibiu Timisoara Arad Oradea Zerind Sibiu Timisoara
1. Complete? No! fails in innite-depth spaces, spaces with loops; modify to avoid repeated states along path  complete in nite spaces 2. Time: O(bm) (terrible if m is much larger than d but if solutions are dense, may be much faster than breadth-rst) 3. Space: O(bm), i.e. linear space! 4. Optimal? No, can nd suboptimal solutions rst.
Expands nodes like Depth First Search but imposes a cutoff on the maximum depth of path. 1. Complete? Yes (no innite loops anymore) 2. Time: O(bk), where k is the depth limit 3. Space: O(bk), i.e. linear space similar to DFS 4. Optimal? No, can nd suboptimal solutions rst Problem: How to pick a good limit ?
1. Tries to combine the benets of depth-rst (low memory) and breadth-rst (optimal and complete) by doing a series of depth- limited searches to depth 1, 2, 3, etc. 2. Early states will be expanded multiple times, but that might not matter too much because most of the nodes are near the leaves.
Arad Zerind Sibiu Timisoara
Arad Zerind Sibiu Timisoara Arad Oradea Arad Oradea Fagaras Rimnicu  Vilcea Arad Lugoj
1. Complete? Yes. 2. Time: nodes at the bottom level are expanded once, nodes at the next level twice, and so on:  depth-limited: 1 + b1 + b2 + . . . + bd1 + bd = O(bd)  iterative deepening: (d + 1)b0 + db1 + (d  1)b2 + . . . + 2  bd1 + 1  bd = O(bd) (We assume b > 1)
1. Complete? Yes. 2. Time: nodes at the bottom level are expanded once, nodes at the next level twice, and so on:  depth-limited: 1 + b1 + b2 + . . . + bd1 + bd = O(bd)  iterative deepening: (d + 1)b0 + db1 + (d  1)b2 + . . . + 2  bd1 + 1  bd = O(bd)  example b = 10, d = 5 :  depth-limited: 1 + 10 + 100 + 1, 000 + 10, 000 + 100, 000 = 111,111  iterative-deepening: 6 + 50 + 400 + 3, 000 + 20, 000 + 100, 000 = 123,456  only about 11% more nodes (for b = 10).
1. Complete? Yes 2. Time: O(bd) 3. Space: O(bd) 4. Optimal? Yes, if step costs are identical.
Start Goal
1. Idea: Search both forward from the initial state and backward from the goal, and stop when the two searches meet in the middle. 2. We need an efcient way to check if a new node already appears in the other half of the search. The complexity analysis assumes this can be done in constant time, using a Hash Table. 3. Assume branching factor = b in both directions and that there is a solution at depth = d. Then bidirectional search nds a solution in O(2bd/2) = O(bd/2) time steps.
1. searching backwards means generating predecessors starting from the goal, which may be difcult 2. there can be several goals  e.g. chekmate positions in chess 3. space complexity: O(bd/2) because the nodes of at least one half must be kept in memory.
1. problem formulation usually requires abstracting away real-world details to dene a state space that can feasibly be explored. 2. variety of Uninformed search strategies 3. Iterative Deepening Search uses only linear space and not much more time than other Uninformed algorithms.
Breadth- Uniform- Depth- Depth- Iterative Criterion Time Space Complete? Optimal ? First O(bd) O(bd) Yes1 Yes3 Cost First O(bC/) O(bm) O(bC/) O(bm) Yes2 Yes No No Limited Deepening O(bk) O(bk) No No O(bd) O(bd) Yes1 Yes3 b = branching factor, d = depth of the shallowest solution, m = maximum depth of the search tree, k = depth limit. 1 = complete if b is nite. 2 = complete if b is nite and step costs   with  > 0. 3 = optimal if actions all have the same cost.
